{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning & Art: Neural Style Transfer\n",
    "\n",
    "Welcome to the Week 4 assignment! In this lab assignment, you will learn about Neural Style Transfer, an algorithm created by [Gatys et al. (2015).](https://arxiv.org/abs/1508.06576)\n",
    "\n",
    "**Upon completion of this assignment, you will be able to:**\n",
    "- Implement the neural style transfer algorithm \n",
    "- Generate novel artistic images using your algorithm \n",
    "- Define the style cost function for Neural Style Transfer\n",
    "- Define the content cost function for Neural Style Transfer\n",
    "\n",
    "Most of the algorithms you've studied optimize a cost function to get a set of parameter values. With Neural Style Transfer, you'll get to optimize a cost function to get pixel values. Exciting!\n",
    "\n",
    "## Important Note on Submission to the AutoGrader\n",
    "\n",
    "Before submitting your assignment to the AutoGrader, please make sure you are not doing the following:\n",
    "\n",
    "1. You have not added any _extra_ `print` statement(s) in the assignment.\n",
    "2. You have not added any _extra_ code cell(s) in the assignment.\n",
    "3. You have not changed any of the function parameters.\n",
    "4. You are not using any global variables inside your graded exercises. Unless specifically instructed to do so, please refrain from it and use the local variables instead.\n",
    "5. You are not changing the assignment code where it is not required, like creating _extra_ variables.\n",
    "\n",
    "If you do any of the following, you will get something like, `Grader not found` (or similarly unexpected) error upon submitting your assignment. Before asking for help/debugging the errors in your assignment, check for these first. If this is the case, and you don't remember the changes you have made, you can get a fresh copy of the assignment by following these [instructions](https://www.coursera.org/learn/convolutional-neural-networks/supplement/DS4yP/h-ow-to-refresh-your-workspace)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [1 - Packages](#1)\n",
    "- [2 - Problem Statement](#2)\n",
    "- [3 - Transfer Learning](#3)\n",
    "- [4 - Neural Style Transfer (NST)](#4)\n",
    "    - [4.1 - Computing the Content Cost](#4-1)\n",
    "        - [4.1.1 - Make Generated Image G Match the Content of Image C](#4-1-1)\n",
    "        - [4.1.2 - Content Cost Function  ùêΩùëêùëúùëõùë°ùëíùëõùë°(ùê∂,ùê∫)](#4-1-2)\n",
    "            - [Excercise 1 - compute_content_cost](#ex-1)\n",
    "    - [4.2 - Computing the Style Cost](#4-2)\n",
    "        - [4.2.1 - Style Matrix](#4-2-1)\n",
    "            - [Exercise 2 - gram_matrix](#ex-2)\n",
    "        - [4.2.2 - Style Cost](#4-2-2)\n",
    "            - [Exercise 3 - compute_layer_style_cost](#ex-3)\n",
    "        - [4.2.3 Style Weights](#4-2-3)\n",
    "            - [Exercise 4 - compute_style_cost](#ex-4)\n",
    "    - [4.3 - Defining the Total Cost to Optimize](#4-3)\n",
    "        - [Exercise 5 - total_cost](#ex-5)\n",
    "- [5 - Solving the Optimization Problem](#5)\n",
    "    - [5.1 Load the Content Image](#5-1)\n",
    "    - [5.2 Load the Style Image](#5-2)\n",
    "    - [5.3 Randomly Initialize the Image to be Generated](#5-3)\n",
    "    - [5.4 - Load Pre-trained VGG19 Model](#5-4)\n",
    "    - [5.5 - Compute Total Cost](#5-5)\n",
    "        - [5.5.1 - Compute Content Cost](#5-5-1)\n",
    "        - [5.5.2 - Compute Style Cost](#5-5-2)\n",
    "            - [Exercise 6 - train_step](#ex-6)\n",
    "    - [5.6 - Train the Model](#5-6)\n",
    "- [6 - Test With Your Own Image (Optional/Ungraded)](#6)\n",
    "- [7 - References](#7)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Packages\n",
    "\n",
    "Run the following code cell to import the necessary packages and dependencies you will need to perform Neural Style Transfer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework.ops import EagerTensor\n",
    "import pprint\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Problem Statement\n",
    "\n",
    "Neural Style Transfer (NST) is one of the most fun and interesting optimization techniques in deep learning. It merges two images, namely: a <strong>\"content\" image (C)</strong> and a <strong>\"style\" image (S)</strong>, to create a <strong>\"generated\" image (G)</strong>. The generated image G combines the \"content\" of the image C with the \"style\" of image S. \n",
    "\n",
    "In this assignment, you are going to combine the Louvre museum in Paris (content image C) with the impressionist style of Claude Monet (content image S) to generate the following image:\n",
    "\n",
    "<img src=\"images/louvre_generated.png\" style=\"width:750px;height:200px;\">\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - Transfer Learning\n",
    "\n",
    "\n",
    "Neural Style Transfer (NST) uses a previously trained convolutional network, and builds on top of that. The idea of using a network trained on a different task and applying it to a new task is called transfer learning. \n",
    "\n",
    "You will be using the the epynomously named VGG network from the [original NST paper](https://arxiv.org/abs/1508.06576) published by the Visual Geometry Group at University of Oxford in 2014. Specifically, you'll use VGG-19, a 19-layer version of the VGG network. This model has already been trained on the very large ImageNet database, and has learned to recognize a variety of low level features (at the shallower layers) and high level features (at the deeper layers). \n",
    "\n",
    "Run the following code to load parameters from the VGG model. This may take a few seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(272) # DO NOT CHANGE THIS VALUE\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "img_size = 400\n",
    "vgg = tf.keras.applications.VGG19(include_top=False,\n",
    "                                  input_shape=(img_size, img_size, 3),\n",
    "                                  weights='pretrained-model/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "\n",
    "vgg.trainable = False\n",
    "pp.pprint(vgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## 4 - Neural Style Transfer (NST)\n",
    "\n",
    "Next, you will be building the Neural Style Transfer (NST) algorithm in three steps:\n",
    "\n",
    "- First, you will build the content cost function $J_{content}(C,G)$\n",
    "- Second, you will build the style cost function $J_{style}(S,G)$\n",
    "- Finally, you'll put it all together to get $J(G) = \\alpha J_{content}(C,G) + \\beta J_{style}(S,G)$. Exciting!\n",
    "\n",
    "<a name='4-1'></a>\n",
    "### 4.1 - Computing the Content Cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4-1-1'></a>\n",
    "#### 4.1.1 - Make Generated Image G Match the Content of Image C\n",
    "\n",
    "One goal you should aim for when performing NST is for the content in generated image G to match the content of image C. To do so, you'll need an understanding of <b> shallow versus deep layers </b>:\n",
    "\n",
    "* The shallower layers of a ConvNet tend to detect lower-level features such as <i>edges and simple textures</i>.\n",
    "* The deeper layers tend to detect higher-level features such as more <i> complex textures and object classes</i>. \n",
    "\n",
    "#### To choose a \"middle\" activation layer $a^{[l]}$ :\n",
    "You need the \"generated\" image G to have similar content as the input image C. Suppose you have chosen some layer's activations to represent the content of an image. \n",
    "* In practice, you'll get the most visually pleasing results if you choose a layer in the <b>middle</b> of the network--neither too shallow nor too deep. This ensures that the network detects both higher-level and lower-level features.\n",
    "* After you have finished this exercise, feel free to come back and experiment with using different layers to see how the results vary!\n",
    "\n",
    "#### To forward propagate image \"C:\"\n",
    "* Set the image C as the input to the pretrained VGG network, and run forward propagation.  \n",
    "* Let $a^{(C)}$ be the hidden layer activations in the layer you had chosen. (In lecture, this was written as $a^{[l](C)}$, but here the superscript $[l]$ is dropped to simplify the notation.) This will be an $n_H \\times n_W \\times n_C$ tensor.\n",
    "\n",
    "#### To forward propagate image \"G\":\n",
    "* Repeat this process with the image G: Set G as the input, and run forward progation. \n",
    "* Let $a^{(G)}$ be the corresponding hidden layer activation. \n",
    "\n",
    "In this running example, the content image C will be the picture of the Louvre Museum in Paris. Run the code below to see a picture of the Louvre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_image = Image.open(\"images/louvre.jpg\")\n",
    "print(\"The content image (C) shows the Louvre museum's pyramid surrounded by old Paris buildings, against a sunny sky with a few clouds.\")\n",
    "content_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4-1-2'></a>\n",
    "#### 4.1.2 - Content Cost Function $J_{content}(C,G)$\n",
    "One goal you should aim for when performing NST is for the content in generated image G to match the content of image C. A method to achieve this is to calculate the content cost function, which will be defined as:\n",
    "\n",
    "$$J_{content}(C,G) =  \\frac{1}{4 \\times n_H \\times n_W \\times n_C}\\sum _{ \\text{all entries}} (a^{(C)} - a^{(G)})^2\\tag{1} $$\n",
    "\n",
    "* Here, $n_H, n_W$ and $n_C$ are the height, width and number of channels of the hidden layer you have chosen, and appear in a normalization term in the cost. \n",
    "* For clarity, note that $a^{(C)}$ and $a^{(G)}$ are the 3D volumes corresponding to a hidden layer's activations. \n",
    "* In order to compute the cost $J_{content}(C,G)$, it might also be convenient to unroll these 3D volumes into a 2D matrix, as shown below.\n",
    "* Technically this unrolling step isn't needed to compute $J_{content}$, but it will be good practice for when you do need to carry out a similar operation later for computing the style cost $J_{style}$.\n",
    "\n",
    "<img src=\"images/NST_LOSS.png\" style=\"width:800px;height:400px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-1'></a>\n",
    "### Excercise 1 - compute_content_cost\n",
    "\n",
    "Compute the \"content cost\" using TensorFlow. \n",
    "\n",
    "**Instructions**: \n",
    "\n",
    "`a_G`: hidden layer activations representing content of the image G\n",
    "<br>\n",
    "`a_C`: hidden layer activations representing content of the image C \n",
    "\n",
    "The 3 steps to implement this function are:\n",
    "1. Retrieve dimensions from `a_G`: \n",
    "    - To retrieve dimensions from a tensor `X`, use: `X.get_shape().as_list()`\n",
    "2. Unroll `a_C` and `a_G` as explained in the picture above\n",
    "    - You'll likely want to use these functions: [tf.transpose](https://www.tensorflow.org/api_docs/python/tf/transpose) and [tf.reshape](https://www.tensorflow.org/api_docs/python/tf/reshape).\n",
    "3. Compute the content cost:\n",
    "    - You'll likely want to use these functions: [tf.reduce_sum](https://www.tensorflow.org/api_docs/python/tf/reduce_sum), [tf.square](https://www.tensorflow.org/api_docs/python/tf/square) and [tf.subtract](https://www.tensorflow.org/api_docs/python/tf/subtract).\n",
    "    \n",
    "    \n",
    "#### Additional Hints for \"Unrolling\"\n",
    "* To unroll the tensor, you want the shape to change from $(m,n_H,n_W,n_C)$ to $(m, n_H \\times n_W, n_C)$.\n",
    "* `tf.reshape(tensor, shape)` takes a list of integers that represent the desired output shape.\n",
    "* For the `shape` parameter, a `-1` tells the function to choose the correct dimension size so that the output tensor still contains all the values of the original tensor.\n",
    "* So `tf.reshape(a_C, shape=[m, n_H * n_W, n_C])` gives the same result as `tf.reshape(a_C, shape=[m, -1, n_C])`.\n",
    "* If you prefer to re-order the dimensions, you can use `tf.transpose(tensor, perm)`, where `perm` is a list of integers containing the original index of the dimensions. \n",
    "* For example, `tf.transpose(a_C, perm=[0,3,1,2])` changes the dimensions from $(m, n_H, n_W, n_C)$ to $(m, n_C, n_H, n_W)$.\n",
    "<!-- * There is more than one way you can unroll a tensor.  -->\n",
    "* Again, note that you don't necessarily need `tf.transpose` to 'unroll' the tensors in this case but this is a useful function to practice and understand for other situations that you'll encounter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3d3bfd0678816054",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# UNQ_C1\n",
    "# GRADED FUNCTION: compute_content_cost\n",
    "\n",
    "def compute_content_cost(content_output, generated_output):\n",
    "    \"\"\"\n",
    "    Computes the content cost\n",
    "    \n",
    "    Arguments:\n",
    "    a_C -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image C \n",
    "    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing content of the image G\n",
    "    \n",
    "    Returns: \n",
    "    J_content -- scalar that you compute using equation 1 above.\n",
    "    \"\"\"\n",
    "    a_C = content_output[-1]\n",
    "    a_G = generated_output[-1]\n",
    "    \n",
    "    ###¬†START CODE HERE\n",
    "    \n",
    "    # Retrieve dimensions from a_G (‚âà1 line)\n",
    "    _, n_H, n_W, n_C = None\n",
    "    \n",
    "    # Reshape a_C and a_G (‚âà2 lines)\n",
    "    a_C_unrolled = None\n",
    "    a_G_unrolled = None\n",
    "    \n",
    "    # compute the cost with tensorflow (‚âà1 line)\n",
    "    J_content = None\n",
    "    \n",
    "    ###¬†END CODE HERE\n",
    "    \n",
    "    return J_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-d97f213fa1c1ba56",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "a_C = tf.random.normal([1, 1, 4, 4, 3], mean=1, stddev=4)\n",
    "a_G = tf.random.normal([1, 1, 4, 4, 3], mean=1, stddev=4)\n",
    "J_content = compute_content_cost(a_C, a_G)\n",
    "J_content_0 = compute_content_cost(a_C, a_C)\n",
    "assert type(J_content) == EagerTensor, \"Use the tensorflow function\"\n",
    "assert np.isclose(J_content_0, 0.0), \"Wrong value. compute_content_cost(A, A) must be 0\"\n",
    "assert np.isclose(J_content, 7.0568767), f\"Wrong value. Expected {7.0568767},  current{J_content}\"\n",
    "\n",
    "print(\"J_content = \" + str(J_content))\n",
    "\n",
    "# Test that it works with symbolic tensors\n",
    "ll = tf.keras.layers.Dense(8, activation='relu', input_shape=(1, 4, 4, 3))\n",
    "model_tmp = tf.keras.models.Sequential()\n",
    "model_tmp.add(ll)\n",
    "try:\n",
    "    compute_content_cost(ll.output, ll.output)\n",
    "    print(\"\\033[92mAll tests passed\")\n",
    "except Exception as inst:\n",
    "    print(\"\\n\\033[91mDon't use the numpy API inside compute_content_cost\\n\")\n",
    "    print(inst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <b>J_content</b>  \n",
    "        </td>\n",
    "        <td>\n",
    "            7.0568767\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! You've now successfully calculated the content cost function!\n",
    "\n",
    "<br>\n",
    "<font color = 'blue'>\n",
    "    \n",
    "**What you should remember:**\n",
    "    \n",
    "- The content cost takes a hidden layer activation of the neural network, and measures how different $a^{(C)}$ and $a^{(G)}$ are. \n",
    "- When you minimize the content cost later, this will help make sure $G$ has similar content as $C$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4-2'></a>\n",
    "### 4.2 - Computing the Style Cost\n",
    "\n",
    "For the running example, you will use the following style image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = Image.open(\"images/monet_800600.jpg\")\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was painted in the style of <b>[impressionism](https://en.wikipedia.org/wiki/Impressionism)</b>.\n",
    "\n",
    "Now let's see how you can now define a \"style\" cost function $J_{style}(S,G)$!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4-2-1'></a>\n",
    "#### 4.2.1 - Style Matrix\n",
    "\n",
    "#### Gram matrix\n",
    "* The style matrix is also called a \"Gram matrix.\" \n",
    "* In linear algebra, the Gram matrix G of a set of vectors $(v_{1},\\dots ,v_{n})$ is the matrix of dot products, whose entries are ${\\displaystyle G_{ij} = v_{i}^T v_{j} = np.dot(v_{i}, v_{j})  }$. \n",
    "* In other words, $G_{ij}$ compares how similar $v_i$ is to $v_j$: If they are highly similar, you would expect them to have a large dot product, and thus for $G_{ij}$ to be large. \n",
    "\n",
    "#### Two meanings of the variable $G$\n",
    "* Note that there is an unfortunate collision in the variable names used here. Following the common terminology used in the literature: \n",
    "    * $G$ is used to denote the Style matrix (or Gram matrix) \n",
    "    * $G$ also denotes the generated image. \n",
    "* For the sake of clarity, in this assignment $G_{gram}$ will be used to refer to the Gram matrix, and $G$ to denote the generated image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Compute Gram matrix $G_{gram}$\n",
    "You will compute the Style matrix by multiplying the \"unrolled\" filter matrix with its transpose:\n",
    "\n",
    "<img src=\"images/NST_GM.png\" style=\"width:900px;height:300px;\">\n",
    "\n",
    "$$\\mathbf{G}_{gram} = \\mathbf{A}_{unrolled} \\mathbf{A}_{unrolled}^T$$\n",
    "\n",
    "#### $G_{(gram)ij}$: correlation\n",
    "The result is a matrix of dimension $(n_C,n_C)$ where $n_C$ is the number of filters (channels). The value $G_{(gram)i,j}$ measures how similar the activations of filter $i$ are to the activations of filter $j$. \n",
    "\n",
    "#### $G_{(gram),ii}$: prevalence of patterns or textures\n",
    "* The diagonal elements $G_{(gram)ii}$ measure how \"active\" a filter $i$ is. \n",
    "* For example, suppose filter $i$ is detecting vertical textures in the image. Then $G_{(gram)ii}$ measures how common  vertical textures are in the image as a whole.\n",
    "* If $G_{(gram)ii}$ is large, this means that the image has a lot of vertical texture. \n",
    "\n",
    "\n",
    "By capturing the prevalence of different types of features ($G_{(gram)ii}$), as well as how much different features occur together ($G_{(gram)ij}$), the Style matrix $G_{gram}$ measures the style of an image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-2'></a>\n",
    "### Exercise 2 - gram_matrix\n",
    "* Using TensorFlow, implement a function that computes the Gram matrix of a matrix A. \n",
    "    * The formula is: The gram matrix of A is $G_A = AA^T$. \n",
    "* You may want to use these functions: [matmul](https://www.tensorflow.org/api_docs/python/tf/matmul) and [transpose](https://www.tensorflow.org/api_docs/python/tf/transpose)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-332b0f746ef0069e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# UNQ_C2\n",
    "# GRADED FUNCTION: gram_matrix\n",
    "\n",
    "def gram_matrix(A):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    A -- matrix of shape (n_C, n_H*n_W)\n",
    "    \n",
    "    Returns:\n",
    "    GA -- Gram matrix of A, of shape (n_C, n_C)\n",
    "    \"\"\"  \n",
    "    ###¬†START CODE HERE\n",
    "    \n",
    "    #(‚âà1 line)\n",
    "    GA = None\n",
    "    \n",
    "    ###¬†END CODE HERE\n",
    "\n",
    "    return GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-fe029fb7600c3fca",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "A = tf.random.normal([3, 2 * 1], mean=1, stddev=4)\n",
    "GA = gram_matrix(A)\n",
    "\n",
    "assert type(GA) == EagerTensor, \"Use the tensorflow function\"\n",
    "assert GA.shape == (3, 3), \"Wrong shape. Check the order of the matmul parameters\"\n",
    "assert np.allclose(GA[0,:], [63.1888, -26.721275, -7.7320204]), \"Wrong values.\"\n",
    "\n",
    "print(\"GA = \\n\" + str(GA))\n",
    "\n",
    "print(\"\\033[92mAll tests passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <b>GA</b>\n",
    "        </td>\n",
    "        <td>\n",
    "           [[ 63.1888    -26.721275   -7.7320204] <br>\n",
    " [-26.721275   12.76758    -2.5158243] <br>\n",
    " [ -7.7320204  -2.5158243  23.752384 ]] <br>\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4-2-2'></a>\n",
    "#### 4.2.2 - Style Cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now know how to calculate the Gram matrix. Congrats! Your next goal will be to minimize the distance between the Gram matrix of the \"style\" image S and the Gram matrix of the \"generated\" image G. \n",
    "* For now, you will use only a single hidden layer $a^{[l]}$.  \n",
    "* The corresponding style cost for this layer is defined as: \n",
    "\n",
    "$$J_{style}^{[l]}(S,G) = \\frac{1}{4 \\times {n_C}^2 \\times (n_H \\times n_W)^2} \\sum _{i=1}^{n_C}\\sum_{j=1}^{n_C}(G^{(S)}_{(gram)i,j} - G^{(G)}_{(gram)i,j})^2\\tag{2} $$\n",
    "\n",
    "* $G_{gram}^{(S)}$ Gram matrix of the \"style\" image.\n",
    "* $G_{gram}^{(G)}$ Gram matrix of the \"generated\" image.\n",
    "* Make sure you remember that this cost is computed using the hidden layer activations for a particular hidden layer in the network $a^{[l]}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-3'></a>\n",
    "### Exercise 3 - compute_layer_style_cost\n",
    "Compute the style cost for a single layer. \n",
    "\n",
    "**Instructions**: The 3 steps to implement this function are:\n",
    "1. Retrieve dimensions from the hidden layer activations a_G: \n",
    "    - To retrieve dimensions from a tensor X, use: `X.get_shape().as_list()`\n",
    "2. Unroll the hidden layer activations a_S and a_G into 2D matrices, as explained in the picture above (see the images in the sections \"computing the content cost\" and \"style matrix\").\n",
    "    - You may use [tf.transpose](https://www.tensorflow.org/api_docs/python/tf/transpose) and [tf.reshape](https://www.tensorflow.org/api_docs/python/tf/reshape).\n",
    "3. Compute the Style matrix of the images S and G. (Use the function you had previously written.) \n",
    "4. Compute the Style cost:\n",
    "    - You may find [tf.reduce_sum](https://www.tensorflow.org/api_docs/python/tf/reduce_sum), [tf.square](https://www.tensorflow.org/api_docs/python/tf/square) and [tf.subtract](https://www.tensorflow.org/api_docs/python/tf/subtract) useful.\n",
    "    \n",
    "    \n",
    "#### Additional Hints\n",
    "* Since the activation dimensions are $(m, n_H, n_W, n_C)$ whereas the desired unrolled matrix shape is $(n_C, n_H*n_W)$, the order of the filter dimension $n_C$ is changed.  So `tf.transpose` can be used to change the order of the filter dimension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8f37df6f128c1f99",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# UNQ_C3\n",
    "# GRADED FUNCTION: compute_layer_style_cost\n",
    "\n",
    "def compute_layer_style_cost(a_S, a_G):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    a_S -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image S \n",
    "    a_G -- tensor of dimension (1, n_H, n_W, n_C), hidden layer activations representing style of the image G\n",
    "    \n",
    "    Returns: \n",
    "    J_style_layer -- tensor representing a scalar value, style cost defined above by equation (2)\n",
    "    \"\"\"\n",
    "    ###¬†START CODE HERE\n",
    "    \n",
    "    # Retrieve dimensions from a_G (‚âà1 line)\n",
    "    _, n_H, n_W, n_C = None\n",
    "    \n",
    "    # Reshape the images from (n_H * n_W, n_C) to have them of shape (n_C, n_H * n_W) (‚âà2 lines)\n",
    "    a_S = None\n",
    "    a_G = None\n",
    "\n",
    "    # Computing gram_matrices for both images S and G (‚âà2 lines)\n",
    "    GS = None\n",
    "    GG = None\n",
    "\n",
    "    # Computing the loss (‚âà1 line)\n",
    "    J_style_layer = None\n",
    "    #J_style_layer = None\n",
    "    \n",
    "    ###¬†END CODE HERE\n",
    "    \n",
    "    return J_style_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-780a4420d8e9eeb2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "a_S = tf.random.normal([1, 4, 4, 3], mean=1, stddev=4)\n",
    "a_G = tf.random.normal([1, 4, 4, 3], mean=1, stddev=4)\n",
    "J_style_layer_GG = compute_layer_style_cost(a_G, a_G)\n",
    "J_style_layer_SG = compute_layer_style_cost(a_S, a_G)\n",
    "\n",
    "\n",
    "assert type(J_style_layer_GG) == EagerTensor, \"Use the tensorflow functions\"\n",
    "assert np.isclose(J_style_layer_GG, 0.0), \"Wrong value. compute_layer_style_cost(A, A) must be 0\"\n",
    "assert J_style_layer_SG > 0, \"Wrong value. compute_layer_style_cost(A, B) must be greater than 0 if A != B\"\n",
    "assert np.isclose(J_style_layer_SG, 14.017805), \"Wrong value.\"\n",
    "\n",
    "print(\"J_style_layer = \" + str(J_style_layer_SG))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <b>J_style_layer</b>\n",
    "        </td>\n",
    "        <td>\n",
    "           14.017805\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4-2-3'></a>\n",
    "#### 4.2.3 Style Weights\n",
    "\n",
    "* So far you have captured the style from only one layer. \n",
    "* You'll get better results if you \"merge\" style costs from several different layers. \n",
    "* Each layer will be given weights ($\\lambda^{[l]}$) that reflect how much each layer will contribute to the style.\n",
    "* After completing this exercise, feel free to come back and experiment with different weights to see how it changes the generated image $G$.\n",
    "* By default, give each layer equal weight, and the weights add up to 1.  ($\\sum_{l}^L\\lambda^{[l]} = 1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by listing the layer names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg.layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a look at the output of a layer `block5_conv4`. You will later define this as the content layer, which will represent the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.get_layer('block5_conv4').output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now choose layers to represent the style of the image and assign style costs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STYLE_LAYERS = [\n",
    "    ('block1_conv1', 0.2),\n",
    "    ('block2_conv1', 0.2),\n",
    "    ('block3_conv1', 0.2),\n",
    "    ('block4_conv1', 0.2),\n",
    "    ('block5_conv1', 0.2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can combine the style costs for different layers as follows:\n",
    "\n",
    "$$J_{style}(S,G) = \\sum_{l} \\lambda^{[l]} J^{[l]}_{style}(S,G)$$\n",
    "\n",
    "where the values for $\\lambda^{[l]}$ are given in `STYLE_LAYERS`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-4'></a>\n",
    "### Exercise 4 -  compute_style_cost\n",
    "Compute style cost\n",
    "\n",
    "<b> Instructions: </b>\n",
    "* A compute_style_cost(...) function has already been implemented. \n",
    "* It calls your `compute_layer_style_cost(...)` several times, and weights their results using the values in `STYLE_LAYERS`. \n",
    "* Please read over it to make sure you understand what it's doing. \n",
    "\n",
    "#### Description of `compute_style_cost`\n",
    "For each layer:\n",
    "* Select the activation (the output tensor) of the current layer.\n",
    "* Get the style of the style image \"S\" from the current layer.\n",
    "* Get the style of the generated image \"G\" from the current layer.\n",
    "* Compute the \"style cost\" for the current layer\n",
    "* Add the weighted style cost to the overall style cost (J_style)\n",
    "\n",
    "Once you're done with the loop:  \n",
    "* Return the overall style cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_style_cost(style_image_output, generated_image_output, STYLE_LAYERS=STYLE_LAYERS):\n",
    "    \"\"\"\n",
    "    Computes the overall style cost from several chosen layers\n",
    "    \n",
    "    Arguments:\n",
    "    style_image_output -- our tensorflow model\n",
    "    generated_image_output --\n",
    "    STYLE_LAYERS -- A python list containing:\n",
    "                        - the names of the layers we would like to extract style from\n",
    "                        - a coefficient for each of them\n",
    "    \n",
    "    Returns: \n",
    "    J_style -- tensor representing a scalar value, style cost defined above by equation (2)\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize the overall style cost\n",
    "    J_style = 0\n",
    "\n",
    "    # Set a_S to be the hidden layer activation from the layer we have selected.\n",
    "    # The last element of the array contains the content layer image, which must not be used.\n",
    "    a_S = style_image_output[:-1]\n",
    "\n",
    "    # Set a_G to be the output of the choosen hidden layers.\n",
    "    # The last element of the list contains the content layer image which must not be used.\n",
    "    a_G = generated_image_output[:-1]\n",
    "    for i, weight in zip(range(len(a_S)), STYLE_LAYERS):  \n",
    "        # Compute style_cost for the current layer\n",
    "        J_style_layer = compute_layer_style_cost(a_S[i], a_G[i])\n",
    "\n",
    "        # Add weight * J_style_layer of this layer to overall style cost\n",
    "        J_style += weight[1] * J_style_layer\n",
    "\n",
    "    return J_style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you choose the coefficients for each layer? The deeper layers capture higher-level concepts, and the features in the deeper layers are less localized in the image relative to each other. So if you want the generated image to softly follow the style image, try choosing larger weights for deeper layers and smaller weights for the first layers. In contrast, if you want the generated image to strongly follow the style image, try choosing smaller weights for deeper layers and larger weights for the first layers.\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<font color = 'blue'>\n",
    "    \n",
    "**What you should remember:**\n",
    "    \n",
    "- The style of an image can be represented using the Gram matrix of a hidden layer's activations. \n",
    "- You get even better results by combining this representation from multiple different layers. \n",
    "- This is in contrast to the content representation, where usually using just a single hidden layer is sufficient.\n",
    "- Minimizing the style cost will cause the image $G$ to follow the style of the image $S$. \n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4-3'></a>\n",
    "### 4.3 - Defining the Total Cost to Optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you will create a cost function that minimizes both the style and the content cost. The formula is: \n",
    "\n",
    "$$J(G) = \\alpha J_{content}(C,G) + \\beta J_{style}(S,G)$$\n",
    "\n",
    "<a name='ex-5'></a>\n",
    "### Exercise 5 - total_cost\n",
    "\n",
    "Implement the total cost function which includes both the content cost and the style cost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-55270d5342632932",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# UNQ_C4\n",
    "# GRADED FUNCTION: total_cost\n",
    "@tf.function()\n",
    "def total_cost(J_content, J_style, alpha = 10, beta = 40):\n",
    "    \"\"\"\n",
    "    Computes the total cost function\n",
    "    \n",
    "    Arguments:\n",
    "    J_content -- content cost coded above\n",
    "    J_style -- style cost coded above\n",
    "    alpha -- hyperparameter weighting the importance of the content cost\n",
    "    beta -- hyperparameter weighting the importance of the style cost\n",
    "    \n",
    "    Returns:\n",
    "    J -- total cost as defined by the formula above.\n",
    "    \"\"\"\n",
    "    ###¬†START CODE HERE\n",
    "    \n",
    "    #(‚âà1 line)\n",
    "    J = None\n",
    "    \n",
    "    ###¬†START CODE HERE\n",
    "\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-81f82cb4147cc92f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "J_content = 0.2    \n",
    "J_style = 0.8\n",
    "J = total_cost(J_content, J_style)\n",
    "\n",
    "assert type(J) == EagerTensor, \"Do not remove the @tf.function() modifier from the function\"\n",
    "assert J == 34, \"Wrong value. Try inverting the order of alpha and beta in the J calculation\"\n",
    "assert np.isclose(total_cost(0.3, 0.5, 3, 8), 4.9), \"Wrong value. Use the alpha and beta parameters\"\n",
    "\n",
    "np.random.seed(1)\n",
    "print(\"J = \" + str(total_cost(np.random.uniform(0, 1), np.random.uniform(0, 1))))\n",
    "\n",
    "print(\"\\033[92mAll tests passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <b>J</b>\n",
    "        </td>\n",
    "        <td>\n",
    "           32.9832\n",
    "        </td>\n",
    "    </tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = 'blue'>\n",
    "    \n",
    "**What you should remember:**\n",
    "- The total cost is a linear combination of the content cost $J_{content}(C,G)$ and the style cost $J_{style}(S,G)$.\n",
    "- $\\alpha$ and $\\beta$ are hyperparameters that control the relative weighting between content and style."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## 5 - Solving the Optimization Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you get to put everything together to implement Neural Style Transfer!\n",
    "\n",
    "\n",
    "Here's what your program be able to do:\n",
    "\n",
    "1. Load the content image \n",
    "2. Load the style image\n",
    "3. Randomly initialize the image to be generated \n",
    "4. Load the VGG19 model\n",
    "5. Compute the content cost\n",
    "6. Compute the style cost\n",
    "7. Compute the total cost\n",
    "8. Define the optimizer and learning rate\n",
    "\n",
    "Here are the individual steps in detail.\n",
    "\n",
    "<a id='part(4)'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5-1'></a>\n",
    "### 5.1 Load the Content Image\n",
    "Run the following code cell to load, reshape, and normalize your \"content\" image C (the Louvre museum picture):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_image = np.array(Image.open(\"images/louvre_small.jpg\").resize((img_size, img_size)))\n",
    "content_image = tf.constant(np.reshape(content_image, ((1,) + content_image.shape)))\n",
    "\n",
    "print(content_image.shape)\n",
    "imshow(content_image[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5-2'></a>\n",
    "### 5.2 Load the Style Image\n",
    "Now load, reshape and normalize your \"style\" image (Claude Monet's painting):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_image =  np.array(Image.open(\"images/monet.jpg\").resize((img_size, img_size)))\n",
    "style_image = tf.constant(np.reshape(style_image, ((1,) + style_image.shape)))\n",
    "\n",
    "print(style_image.shape)\n",
    "imshow(style_image[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5-3'></a>\n",
    "### 5.3 Randomly Initialize the Image to be Generated\n",
    "Now, you get to initialize the \"generated\" image as a noisy image created from the content_image.\n",
    "\n",
    "* The generated image is slightly correlated with the content image.\n",
    "* By initializing the pixels of the generated image to be mostly noise but slightly correlated with the content image, this will help the content of the \"generated\" image more rapidly match the content of the \"content\" image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_image = tf.Variable(tf.image.convert_image_dtype(content_image, tf.float32))\n",
    "noise = tf.random.uniform(tf.shape(generated_image), -0.25, 0.25)\n",
    "generated_image = tf.add(generated_image, noise)\n",
    "generated_image = tf.clip_by_value(generated_image, clip_value_min=0.0, clip_value_max=1.0)\n",
    "\n",
    "print(generated_image.shape)\n",
    "imshow(generated_image.numpy()[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5-4'></a>\n",
    "## 5.4 - Load Pre-trained VGG19 Model\n",
    "Next, as explained in [part(2)](#part(2)), define a function which loads the VGG19 model and returns a list of the outputs for the middle layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_outputs(vgg, layer_names):\n",
    "    \"\"\" Creates a vgg model that returns a list of intermediate output values.\"\"\"\n",
    "    outputs = [vgg.get_layer(layer[0]).output for layer in layer_names]\n",
    "\n",
    "    model = tf.keras.Model([vgg.input], outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, define the content layer and build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_layer = [('block5_conv4', 1)]\n",
    "\n",
    "vgg_model_outputs = get_layer_outputs(vgg, STYLE_LAYERS + content_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the outputs for the content and style layers in separate variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_target = vgg_model_outputs(content_image)  # Content encoder\n",
    "style_targets = vgg_model_outputs(style_image)     # Style enconder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5-5'></a>\n",
    "### 5.5 - Compute Total Cost\n",
    "\n",
    "<a name='5-5-1'></a>\n",
    "#### 5.5.1 - Compute the Content image Encoding (a_C)\n",
    "\n",
    "You've built the model, and now to compute the content cost, you will encode your content image using the appropriate hidden layer activations. Set this encoding to the variable `a_C`. Later in the assignment, you will need to do the proper with the generated image, by setting the variable `a_G` to be the appropriate hidden layer activations. You will use layer `block5_conv4` to compute the encoding. The code below does the following:\n",
    "\n",
    "1. Set a_C to be the tensor giving the hidden layer activation for layer \"block5_conv4\" using the content image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the content image to be the input of the VGG model.  \n",
    "# Set a_C to be the hidden layer activation from the layer we have selected\n",
    "preprocessed_content =  tf.Variable(tf.image.convert_image_dtype(content_image, tf.float32))\n",
    "a_C = vgg_model_outputs(preprocessed_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5-5-2'></a>\n",
    "#### 5.5.2 - Compute the Style image Encoding (a_S) \n",
    "\n",
    "The code below sets a_S to be the tensor giving the hidden layer activation for `STYLE_LAYERS` using our style image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the input of the model to be the \"style\" image \n",
    "preprocessed_style =  tf.Variable(tf.image.convert_image_dtype(style_image, tf.float32))\n",
    "a_S = vgg_model_outputs(preprocessed_style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the utils that you will need to display the images generated by the style transfer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_0_1(image):\n",
    "    \"\"\"\n",
    "    Truncate all the pixels in the tensor to be between 0 and 1\n",
    "    \n",
    "    Arguments:\n",
    "    image -- Tensor\n",
    "    J_style -- style cost coded above\n",
    "\n",
    "    Returns:\n",
    "    Tensor\n",
    "    \"\"\"\n",
    "    return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)\n",
    "\n",
    "def tensor_to_image(tensor):\n",
    "    \"\"\"\n",
    "    Converts the given tensor into a PIL image\n",
    "    \n",
    "    Arguments:\n",
    "    tensor -- Tensor\n",
    "    \n",
    "    Returns:\n",
    "    Image: A PIL image\n",
    "    \"\"\"\n",
    "    tensor = tensor * 255\n",
    "    tensor = np.array(tensor, dtype=np.uint8)\n",
    "    if np.ndim(tensor) > 3:\n",
    "        assert tensor.shape[0] == 1\n",
    "        tensor = tensor[0]\n",
    "    return Image.fromarray(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-6'></a>\n",
    "### Exercise 6 - train_step \n",
    "\n",
    "Implement the train_step() function for transfer learning\n",
    "\n",
    "* Use the Adam optimizer to minimize the total cost `J`.\n",
    "* Use a learning rate of 0.01  \n",
    "* [Adam Optimizer documentation](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam)\n",
    "* You will use [tf.GradientTape](https://www.tensorflow.org/api_docs/python/tf/GradientTape) to update the image. ([Course 2 Week 3: TensorFlow Introduction Assignment](https://www.coursera.org/learn/deep-neural-network/programming/fuJJY/tensorflow-introduction))\n",
    "* Within the tf.GradientTape():\n",
    "   * Compute the encoding of the generated image using vgg_model_outputs. Assing the result to a_G.\n",
    "   * Compute the total cost J, using the global variables a_C, a_S and the local a_G\n",
    "   * Use `alpha = 10` and `beta = 40`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dfbcc4b8f8a959e5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# UNQ_C5\n",
    "# GRADED FUNCTION: train_step\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "@tf.function()\n",
    "def train_step(generated_image):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # In this function you must use the precomputed encoded images a_S and a_C\n",
    "        # Compute a_G as the vgg_model_outputs for the current generated image\n",
    "        \n",
    "        ###¬†START CODE HERE\n",
    "        \n",
    "        #(1 line)\n",
    "        a_G = None\n",
    "        \n",
    "        # Compute the style cost\n",
    "        #(1 line)\n",
    "        J_style = None\n",
    "\n",
    "        #(2 lines)\n",
    "        # Compute the content cost\n",
    "        J_content = None\n",
    "        # Compute the total cost\n",
    "        J = None\n",
    "        \n",
    "        ###¬†END CODE HERE\n",
    "        \n",
    "    grad = tape.gradient(J, generated_image)\n",
    "\n",
    "    optimizer.apply_gradients([(grad, generated_image)])\n",
    "    generated_image.assign(clip_0_1(generated_image))\n",
    "    # For grading purposes\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0b5e78c25be54360",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# You always must run the last cell before this one. You will get an error if not.\n",
    "generated_image = tf.Variable(generated_image)\n",
    "\n",
    "\n",
    "J1 = train_step(generated_image)\n",
    "print(J1)\n",
    "assert type(J1) == EagerTensor, f\"Wrong type {type(J1)} != {EagerTensor}\"\n",
    "assert np.isclose(J1, 25629.055, rtol=0.05), f\"Unexpected cost for epoch 0: {J1} != {25629.055}\"\n",
    "\n",
    "J2 = train_step(generated_image)\n",
    "print(J2)\n",
    "assert np.isclose(J2, 17812.627, rtol=0.05), f\"Unexpected cost for epoch 1: {J2} != {17735.512}\"\n",
    "\n",
    "print(\"\\033[92mAll tests passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**\n",
    "```\n",
    "tf.Tensor(25629.055, shape=(), dtype=float32)\n",
    "tf.Tensor(17735.512, shape=(), dtype=float32)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it's working! Now you'll get to put it all together into one function to better see your results!\n",
    "\n",
    "<a name='5-6'></a>\n",
    "### 5.6 - Train the Model\n",
    "\n",
    "Run the following cell to generate an artistic image. It should take about 3min on a GPU for 2500 iterations. Neural Style Transfer is generally trained using GPUs.\n",
    "\n",
    "If you increase the learning rate you can speed up the style transfer, but often at the cost of quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the generated image at some epochs\n",
    "# Uncoment to reset the style transfer process. You will need to compile the train_step function again \n",
    "epochs = 2501\n",
    "for i in range(epochs):\n",
    "    train_step(generated_image)\n",
    "    if i % 250 == 0:\n",
    "        print(f\"Epoch {i} \")\n",
    "    if i % 250 == 0:\n",
    "        image = tensor_to_image(generated_image)\n",
    "        imshow(image)\n",
    "        image.save(f\"output/image_{i}.jpg\")\n",
    "        plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the following code cell to see the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Show the 3 images in a row\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "imshow(content_image[0])\n",
    "ax.title.set_text('Content image')\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "imshow(style_image[0])\n",
    "ax.title.set_text('Style image')\n",
    "ax = fig.add_subplot(1, 3, 3)\n",
    "imshow(generated_image[0])\n",
    "ax.title.set_text('Generated image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at that! You did it! After running this, in the upper bar of the notebook click on \"File\" and then \"Open\". Go to the \"/output\" directory to see all the saved images. Open \"generated_image\" to see the generated image! :)\n",
    "\n",
    "Running for around 20000 epochs with a learning rate of 0.001, you should see something like the image presented below on the right:\n",
    "\n",
    "<img src=\"images/louvre_generated.png\" style=\"width:800px;height:300px;\">\n",
    "\n",
    "The hyperparameters were set so that you didn't have to wait too long to see an initial result. To get the best looking results, you may want to try running the optimization algorithm longer (and perhaps with a smaller learning rate). After completing and submitting this assignment, come back and play more with this notebook, and see if you can generate even better looking images. But first, give yourself a pat on the back for finishing this long assignment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are few other examples:\n",
    "\n",
    "- The beautiful ruins of the ancient city of Persepolis (Iran) with the style of Van Gogh (The Starry Night)\n",
    "<img src=\"images/perspolis_vangogh.png\" style=\"width:750px;height:300px;\">\n",
    "\n",
    "- The tomb of Cyrus the great in Pasargadae with the style of a Ceramic Kashi from Ispahan.\n",
    "<img src=\"images/pasargad_kashi.png\" style=\"width:750px;height:300px;\">\n",
    "\n",
    "- A scientific study of a turbulent fluid with the style of a abstract blue fluid painting.\n",
    "<img src=\"images/circle_abstract.png\" style=\"width:750px;height:300px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free Up Resources for Other Learners\n",
    "\n",
    "If you don't plan on continuing to the next `Optional` section, help us to provide our learners a smooth learning experience, by freeing up the resources used by your assignment by running the cell below so that the other learners can take advantage of those resources just as much as you did. Thank you!\n",
    "\n",
    "**Note**: \n",
    "- Run the cell below when you are done with the assignment and are ready to submit it for grading.\n",
    "- When you'll run it, a pop up will open, click `Ok`.\n",
    "- Running the cell will `restart the kernel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.save_checkpoint();\n",
    "if (confirm(\"Clear memory?\") == true)\n",
    "{\n",
    "    IPython.notebook.kernel.restart();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "## 6 - Test With Your Own Image (Optional/Ungraded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can also rerun the algorithm on your own images! \n",
    "\n",
    "To do so, go back to part(4) and change the content image and style image with your own pictures. In detail, here's what you should do:\n",
    "\n",
    "1. Click on \"File -> Open\" in the upper tab of the notebook\n",
    "2. Go to \"/images\" and upload your images (images will scaled to 400x400, but you can change that parameter too in section 2), rename them \"my_content.png\" and \"my_style.png\" for example.\n",
    "3. Change the code in [part(4)](#part(4)) from :\n",
    "\n",
    "```py\n",
    "content_image = np.array(Image.open(\"images/louvre_small.jpg\").resize((img_size, img_size)))\n",
    "style_image =  np.array(Image.open(\"images/monet.jpg\").resize((img_size, img_size)))\n",
    "\n",
    "```\n",
    "\n",
    "&emsp;&emsp;to:\n",
    "\n",
    "``` py\n",
    "content_image = np.array(Image.open(\"images/my_content.jpg\").resize((img_size, img_size)))\n",
    "style_image =  np.array(Image.open(\"my_style.jpg\").resize((img_size, img_size)))\n",
    "\n",
    "```\n",
    "4. Rerun the cells (you may need to restart the Kernel in the upper tab of the notebook).\n",
    "\n",
    "You can share your generated images with us on social media with the hashtag #deeplearningAI or by tagging us directly!\n",
    "\n",
    "Here are some ideas on how to tune your hyperparameters: \n",
    "- To select different layers to represent the style, redefine `STYLE_LAYERS`\n",
    "- To alter the number of iterations you want to run the algorithm, try changing `epochs` given in Section 5.6.\n",
    "- To alter the relative weight of content versus style, try altering alpha and beta values\n",
    "\n",
    "Happy coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Free Up Resources for Other Learners\n",
    "\n",
    "In order to provide our learners a smooth learning experience, please free up the resources used by your assignment by running the cell below so that the other learners can take advantage of those resources just as much as you did. Thank you!\n",
    "\n",
    "**Note**: \n",
    "- Run the cell below when you are done with the assignment and are ready to submit it for grading.\n",
    "- When you'll run it, a pop up will open, click `Ok`.\n",
    "- Running the cell will `restart the kernel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.save_checkpoint();\n",
    "if (confirm(\"Clear memory?\") == true)\n",
    "{\n",
    "    IPython.notebook.kernel.restart();\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Great job on completing this assignment! You are now able to use Neural Style Transfer to generate artistic images. This is also your first time building a model in which the optimization algorithm updates the pixel values rather than the neural network's parameters. Deep learning has many different types of models and this is only one of them! \n",
    "\n",
    "<font color = 'blue'>\n",
    "    \n",
    "## What you should remember\n",
    "- Neural Style Transfer is an algorithm that given a content image C and a style image S can generate an artistic image\n",
    "- It uses representations (hidden layer activations) based on a pretrained ConvNet. \n",
    "- The content cost function is computed using one hidden layer's activations.\n",
    "- The style cost function for one layer is computed using the Gram matrix of that layer's activations. The overall style cost function is obtained using several hidden layers.\n",
    "- Optimizing the total cost function results in synthesizing new images. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations on finishing the course!\n",
    "This was the final programming exercise of this course. Congratulations - you've finished all the programming exercises of this course on Convolutional Networks! See you in Course 5, Sequence Models! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='7'></a>\n",
    "## 7 - References\n",
    "\n",
    "The Neural Style Transfer algorithm was due to Gatys et al. (2015). Harish Narayanan and Github user \"log0\" also have highly readable write-ups this lab was inspired by. The pre-trained network used in this implementation is a VGG network, which is due to Simonyan and Zisserman (2015). Pre-trained weights were from the work of the MathConvNet team. \n",
    "\n",
    "- Leon A. Gatys, Alexander S. Ecker, Matthias Bethge, (2015). [A Neural Algorithm of Artistic Style](https://arxiv.org/abs/1508.06576) \n",
    "- Harish Narayanan, [Convolutional neural networks for artistic style transfer.](https://harishnarayanan.org/writing/artistic-style-transfer/)\n",
    "- Log0, [TensorFlow Implementation of \"A Neural Algorithm of Artistic Style\".](http://www.chioka.in/tensorflow-implementation-neural-algorithm-of-artistic-style)\n",
    "- Karen Simonyan and Andrew Zisserman (2015). [Very deep convolutional networks for large-scale image recognition](https://arxiv.org/pdf/1409.1556.pdf)\n",
    "- [MatConvNet.](http://www.vlfeat.org/matconvnet/pretrained/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
